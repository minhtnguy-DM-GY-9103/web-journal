---
layout: post
title: "Reading 2"
date: 2025-03-05 14:09:37 -0500
categories: readings
---

# [Designing AI to Think With Us, Not For Us](https://www.epicpeople.org/designing-ai-to-think-with-us/)

In this reading Stefanie Hutka introduces different approaches on how to design for generative AI. One method she highlights is the cognitive offloading matrix, which allows designers to understand the cognitive load of different tasks and which tasks are best suited for AI.

I think this is a great approach to designing for AI, as it forces designers to think about the cognitive load and context of the task, as AI is not always the best solution for every problem. By using the cognitive offloading matrix, designers can identify the desirable tasks and undesirable tasks. Hutka emphasizes the importance of using AI not as a replacement for human intelligence, but as a tool to augment it and help humans make better decisions.

In my daily work, I often find myself using AI to generate ideas, which can seem like it's offloading the cognitive load to the AI and allowing it to do the thinking for me. However, I think this is a great example of a desirable task, as it allows me to generate a large number of ideas quickly and then manually select the best ones.

In the end humans are the ones who must make the final decisions, and AI is just a tool to help us make better decisions. This leads me to consider agentic AI systems, or those capable of autonomous decision-making. Even with such advanced AI, I believe we would still benefit from applying the cognitive offloading matrix to determine which tasks are appropriate for AI delegation. However, the question then becomes: can we develop enough trust in AI systems to comfortably integrate agentic AI into our daily workflows?

Building this trust relationship between humans and autonomous AI will be a major design challenge in the future of AI interactions.
