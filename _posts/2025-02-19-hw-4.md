---
layout: post
title: "Homework 4"
date: 2025-02-19 14:09:37 -0500
categories: homework
---

The model I chose to explore is MusicGen, a text to music model created by Meta AI.

MusicGen allows you to generate a short music file based on a text prompt and/or a sample music file or from a mic. This model is a generative model that uses a transformer-based architecture to generate music. This model was trained on stock music files. Some technical requirements is that I am using the MusicGen Small model, which only generates about 20 seconds of music.

Some use cases for this model could be:

- Learning music theory
- Generating music for media (podcasts, videos, etc.)
- Creating music samples

To evaluate the model, I created a small python script that processes a text prompt and generates a music file.

For my first prompt, I used "A country song with a heavy drum and bass".

This is the output:

<audio src="/web-journal/assets/generated_music1.wav" controls></audio>

This output sounds like a basic country song, but it seems to be lacking the drum and bass. This may be becuase country music is not typically characterized by heavy drums and bass.
<br><br>

For my second prompt, I used "A rnb happy birthday song at 120bpm".

This is the output:
<audio src="/web-journal/assets/generated_music2.wav" controls></audio>

While this is an example of an rnb song, it is not very good and it does not sound like a happy birthday song. However, it is a good example of how the model can generate music at a specific tempo. I thought it was interesting to hear a beat change in the middle of the song.
<br><br>

For my third prompt, I used "A country happy birthday song". I chose to use a simpler prompt combining the two previous prompts.

This is the output:

<audio src="/web-journal/assets/generated_music3.wav" controls></audio>

This output sounds like an uptempo country song, but it still does not sound like a happy birthday song. However this output has a faster tempo than the first prompt I used for a country song. This makes me wonder if the model associates happy birthday with uptempo music, not the typical happy birthday song.
<br><br>

For the last prompt, I tried to make the prompt as simple as possible. I used "A happy birthday song".

This is the output:

<audio src="/web-journal/assets/generated_music4.wav" controls></audio>

This output still does not sound like a happy birthday song, but it is uptempo and is synthy. I wonder if adding an example audio file would help the model generate a better happy birthday song.
<br><br>

For future uses for this model, I would be interested in seeing how it could pair with another model to generate music. I wonder if it could be paired with an image to music model to generate music based on an image. For example, if I were to upload an image of a beach, the model would generate a beach-themed song. Another use case could be using a face recognition model to generate music based on a person's face emotion.
