---
layout: post
title: "Final Writeup"
date: 2025-05-07 14:09:37 -0500
categories: final
---

### Project Overview

My project is a visual inspiration board that allows users to interact with their saved inspirtation in a more active way. Users can make quick choices between two images at a time, creating a new board with the images selected. Using machine learning and AI, the images are then connected by visual similarity to see different connections between the images. My key design question is: **How might we help creatives better engage with their shared inspiration in a more active way and organize their aesthetic direction based on their current context/project?**

## User Research

For my user research, I conducted two interviews and one observation of a designer seeking inspiration, which highlighted several key pain points in how creative individuals manage visual inspiration. Users tend to collect inspiration from different sources such as Instagram, Pinterest, and screenshots, but struggle with organization due to time constraints and friction in categorization flows. Additionally, many have a "hoarding mentality," saving content they might never use but hesitate to delete. When starting new projects, they face difficulty locating specific references within their collections, especially when inspiration spans multiple sources and styles.

This experience fails to meet emotional needs for effortless organization and the satisfaction of actually utilizing saved content. Functionally, users require a system that simplifies categorization and allows users to revisit their saved inspiration in a more active way.

## Technology

For this project, I used the following tech stack:

- Next.js for the frontend
- MobileNet (google/mobilenet_v2_1.4_224) for image classification
- Hugging Face (openai/clip-vit-base-patch32) for image similarity
- React Flow for the canvas UI

I also experimented with other image classification models, but I found that the MobileNet model was the easiest to work with and I was able to preprocess the images. Although some of the image tags generated were not very accurate, I found that the randomness of the tags can open new ideas and insights that users might not have thought of by just looking at the image.

## Implementation

My solution to this problem is a visual inspiration board that allows users to interact with their saved inspiration in a more active way. Users are able to choose between two random images at a time, creating a new board with the images selected. This way, users can revisit their saved inspiration that they might have forgotten about. Using the images the user selected, a new inspiration board is generated where the images are connected by visual similarity. The more similar the images are, the thicker the connection line is. Additionally, can view tags classified by MobileNet and the core color palette of the image.

## Interface

I experimented with different UI designs for navigating through your collection of inspiration and how to visualize the results. These included a clustered group layout where AI categorizes images, a dating app-inspired swiping interface for image selection, a basic gallery with AI-generated tags and color extraction, a grid layout with theme-based filtering, and a drag-and-drop interface for AI analysis of selected images.

This interface was one of the first ideas I implmented, a stack of images that the users can click through. However, after getting feedback, I realized that this was not as interactive as I wanted it to be.

<br><br>
![Solution 3](/web-journal/assets/images/ui.png)
<br><br>

I was able to get feedback from five users, which revealed that the swiping interface was the most interesting and ended up being the direction I went in. I wanted the user to filter through their inspiration in a more active way, choosing between two images at a time and use their intuition to make quick, creative decisions.

<br><br>
![Solution 3](/web-journal/assets/images/choice.png)
<br><br>

I also experimented with different ways to visualize the similarity between the images. For visualizing the inspiration board, I struggled with this at first, but knew I wanted to generate a starting point for the user to interact with. To better clarify the direction I wanted, I created a mockup of the canvas UI in Figma.

<br><br>
![Solution 3](/web-journal/assets/images/mockup.png)
<br><br>

I decided on a canvas UI where the user can view the generated board, but also interact with the images and organize them in their own way. Here the connections lines between the images visualize the similarity between the images, the more similar the images are, the thicker the connection line is.

<br><br>
![Solution 3](/web-journal/assets/images/canvas.png)
<br><br>

I also chose to use a light UI rather than a dark UI, as I felt the light UI encouraged more exploration on the canvas, while the dark UI felt more enclosed and less inviting.

## System Diagram

<br><br>
![Solution 3](/web-journal/assets/images/diagram.png)
<br><br>

The system diagram above shows the flow of the project. The user can select two images at a time, which are then passed through the MobileNet model to generate tags and the core color palette. The images are then passed through the Hugging Face OpenAI Clip model to generate the similarity values between the images. The similarity values are then used to generate the inspiration board, which is displayed to the user.

## Conclusion

The project works introduces a new way to interact with your content, as the selection interaction makes organization feels more fun than burdensome. Additionnally the randomization of it helps users revisit images they might have forgotten about.

One limitation I encountered was running out of Hugging Face API credits during development. I had to hardcode the similarity values between images to simulate the connections for the demo.

Moving forward, I would like to refine this logic to actually use Clip to generate the similarity values between images. I also want to explore how to incorporate the image tags and color palette into the canvas UI, making them interactive pieves of the inspiration board. I also want to explore collaborative features, enabling multiple users to co-create boards.

I would like to see how people incorporate the project at its current state in their everyday workflow to see what works and what doesn't work for them. I wonder how people would use the project to help them with their creative process and how often they would use it. Overall, even though this project went in a different direction than I had initally planned, I think that this allows for a more active and intuitive way to interact with your saved inspiration, hopefully sparking new connections and ideas.
